{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyObH6PZDBNwyTieA/8OJ+p6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatCat776/InterviewBot/blob/main/interview_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Job Interview Bot\n"
      ],
      "metadata": {
        "id": "3r8L7w0ZWUEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "2rlU2bTEyPxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "BIR9rVbpyZNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet google-genai pandas\n",
        "# not sure I really need pandas\n"
      ],
      "metadata": {
        "id": "YXtPGbBffejR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "u7tV7GkDIi_S"
      },
      "outputs": [],
      "source": [
        "import base64"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure Gemini"
      ],
      "metadata": {
        "id": "q6G85BQoWhTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('AI_STUDIO_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "model = \"gemini-2.5-flash-lite\"\n"
      ],
      "metadata": {
        "id": "ETKSChDxUCKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure google drive"
      ],
      "metadata": {
        "id": "ahwxWv2sZ0L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OnWj_cp9Z2Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Static model settings"
      ],
      "metadata": {
        "id": "ZEX3sM9HWpGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: move resume import here\n",
        "my_instructions = \"\"\"\n",
        "You are a job applicant in a job interview.\n",
        "\"\"\"\n",
        "\n",
        "generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = .5,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 2048,\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    )],\n",
        "    system_instruction=[types.Part.from_text(text=my_instructions)],\n",
        "    thinking_config=types.ThinkingConfig(\n",
        "      thinking_budget=0,\n",
        "    ),\n",
        "  )"
      ],
      "metadata": {
        "id": "8PUHeawVOpGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interview Questions"
      ],
      "metadata": {
        "id": "9rrT8WFLXdyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        types.Part.from_text(text=\"\"\"Please introduce yourself\"\"\")\n",
        "      ]\n",
        "    )\n",
        "  ]"
      ],
      "metadata": {
        "id": "NjL36CO3WO1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer Questions"
      ],
      "metadata": {
        "id": "wuLJCplbWQuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in client.models.generate_content_stream(\n",
        "    model = model,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "    ):\n",
        "    print(chunk.text, end=\"\")"
      ],
      "metadata": {
        "id": "Oea75GRGVTm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions that use my resume, text method"
      ],
      "metadata": {
        "id": "Xgo_dZVHX8ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the content of the text file\n",
        "with open(\"/content/drive/My Drive/text_resume.txt\", \"r\") as f:\n",
        "    text_resume_content = f.read()\n",
        "\n",
        "contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        types.Part.from_text(text=\"\"\"Tell me about the document\"\"\"),\n",
        "        types.Part.from_text(text=text_resume_content), # Include the text content directly\n",
        "        types.Part.from_text(text=\"\"\"Say Boo when done\"\"\")\n",
        "      ]\n",
        "    )\n",
        "  ]\n",
        "\n",
        "# # Response as a stream\n",
        "#for chunk in client.models.generate_content_stream(\n",
        "#    model = model,\n",
        "#    contents = contents,\n",
        "#    config = generate_content_config,\n",
        "#    ):\n",
        "#    print(chunk.text, end=\"\")\n",
        "\n",
        "# Respond as a single answer\n",
        "response = client.models.generate_content(\n",
        "    model=model, contents=contents, config = generate_content_config,\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "JiTOzj5YX7oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions that use my resume, PDF method.\n",
        "Pulling content from google drive and github doesn't seem to work in colab the same way it does in Virtex AI. For some reason, I have to convert the pdf to txt, then I can use it here."
      ],
      "metadata": {
        "id": "UeWuge3Od_iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "id": "fyKJ1O43pt5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def convert_pdf_to_txt_pdfplumber(pdf_path, txt_path):\n",
        "    \"\"\"Converts a PDF file to a plain text file using pdfplumber.\"\"\"\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf, open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            for page in pdf.pages:\n",
        "                text = page.extract_text()\n",
        "                if text:\n",
        "                    f.write(text + '\\n')  # Add a newline to separate pages\n",
        "        print(f\"Text successfully extracted from {pdf_path} to {txt_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting PDF: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "# convert_pdf_to_txt_pdfplumber(\"input.pdf\", \"output.txt\")"
      ],
      "metadata": {
        "id": "_13kT-fKpmwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_pdf_to_txt_pdfplumber(\"/content/drive/My Drive/My_Resume.pdf\", \"/content/drive/My Drive/resume_as_txt.txt\")\n",
        "\n",
        "with open(\"/content/drive/My Drive/resume_as_txt.txt\", \"r\") as f:\n",
        "    text_resume_content = f.read()\n",
        "\n",
        "contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        types.Part.from_text(text=\"\"\"Tell me about the document\"\"\"),\n",
        "        types.Part.from_text(text=text_resume_content), # Include the text content directly\n",
        "        types.Part.from_text(text=\"\"\"Say Boo PDF when done\"\"\")\n",
        "      ]\n",
        "    )\n",
        "  ]\n",
        "\n",
        "\n",
        "\n",
        "for chunk in client.models.generate_content_stream(\n",
        "    model = model,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "    ):\n",
        "    print(chunk.text, end=\"\")"
      ],
      "metadata": {
        "id": "sa9znrOoeB3Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}